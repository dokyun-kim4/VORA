<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Milestone I</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Back to home</a>
					</header>

				<!-- Main -->
					<div id="main">
						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">November 17, 2023</span>
									<h1>Milestone I</h1>
								</header>

								<div class="image main"><img src="" alt="" /></div>
								
								<p>For our first milestone, we wanted to explore different methods for implementing speech-to-text and object identification.</p>

								<h3>Voice Commands</h3>
								<p>
									For milestone 1, we tested two ways of converting auido to text: <a href="https://cloud.google.com/speech-to-text?hl=en">Google Speech-to-Text</a> 
									through the <a href="https://pypi.org/project/SpeechRecognition/">SpeechRecognition python library</a>, 
									and <a href="https://github.com/openai/whisper">OpenAI Whisper</a>. We were able to get both methods working, 
									but we were only able to get OpenAI Whisper to work on prerecorded audio files, while the SpeechRecognition library could transcribe live.
									We may try to use Whisper with the SpeechRecognition library before the next milestone, but for now we will continue with Google's Speech-to-Text.
								</p>
							
								<h3>Object Identification</h3>
								<p>
									<!-- TODO continue writing this section -->
									After researching multiple object identification methods, we settled on using Ultralytic's <a href="https://docs.ultralytics.com/">YOLO v8</a> library.
									The library had models that were pre-trained using the COCO dataset, which includes 80 different daily life objects. For milestone 1, we wrote a Python script that can identify the following
									objects using bounding boxes.
									<ul>
										<li>Bottle</li>
										<li>Cup</li>
										<li>Mouse</li>
										<li>Cell phone</li>
										<li>Book</li>
										<li>Scissors</li>
									</ul>

									<div class="image fit"><img src="images/milestone1.png" alt="YOLO example"></div>
									<div style="text-align: center;">
										<a href="https://github.com/dokyun-kim4/hey-neato/tree/milestone1" class="button primary">View Github Repo</a>
									</div>
								</p>
							</section>

					</div>
				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; VOAR</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>